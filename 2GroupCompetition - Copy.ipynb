{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ad41fa1",
   "metadata": {},
   "source": [
    "### Chuẩn bị dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8a593529-6cab-4016-b88d-9318ef1a71ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels counts in X_train 1879\n",
      "Total rows in test set 498121\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('./data/train.csv', sep='|')\n",
    "df_test = pd.read_csv('./data/test.csv', sep='|')\n",
    "\n",
    "new_df = df.dropna()\n",
    "new_df_test = df_test.dropna()\n",
    "\n",
    "new_df.insert(1, 'totalItemsScanned', new_df['scannedLineItemsPerSecond'] * new_df['totalScanTimeInSeconds'])\n",
    "new_df_test.insert(1, 'totalItemsScanned', new_df_test['scannedLineItemsPerSecond'] * new_df_test['totalScanTimeInSeconds'])\n",
    "\n",
    "y_train = new_df.pop('fraud')\n",
    "\n",
    "X_train = new_df.drop(columns=[\n",
    "    'scannedLineItemsPerSecond', 'lineItemVoidsPerPosition', 'valuePerSecond',\n",
    "    'quantityModifications', 'grandTotal'\n",
    "])\n",
    "X_test = new_df_test.drop(columns=[\n",
    "    'scannedLineItemsPerSecond', 'lineItemVoidsPerPosition', 'valuePerSecond',\n",
    "    'quantityModifications', 'grandTotal'\n",
    "])\n",
    "\n",
    "print('Labels counts in X_train',len(X_train))\n",
    "print('Total rows in test set',len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d5c061",
   "metadata": {},
   "source": [
    "**Chia tập dữ liệu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "da661b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.7, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f8fe7c",
   "metadata": {},
   "source": [
    "**Thực hiện gọi áp dụng mô hình chưa sử dụng siêu tham số**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b4e41cd3-1f4b-4951-a3c6-21db4b050d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Dự đoán kết quả từng mô hình và lưu vào DataFrame\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier(max_depth=3, criterion='gini')\n",
    "dt_model.fit(X_train, y_train)\n",
    "dt_preds_train = dt_model.predict(X_train)\n",
    "dt_preds_val = dt_model.predict(X_val)\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_model = KNeighborsClassifier()\n",
    "knn_model.fit(X_train, y_train)\n",
    "knn_preds_train = knn_model.predict(X_train)\n",
    "knn_preds_val = knn_model.predict(X_val)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=100000 )  # Tăng số vòng lặp tối đa\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_preds_train = lr_model.predict(X_train)\n",
    "lr_preds_val = lr_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dce4e4",
   "metadata": {},
   "source": [
    "### **Đánh giá hiệu suất**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "469d5435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train confusion matrix for Decision Tree model is: \n",
      " [[521   4]\n",
      " [  5  33]]\n",
      "The validation confusion matrix for Decision Tree model is: \n",
      " [[1239   11]\n",
      " [  21   45]]\n",
      "Train accuracy:  0.9840142095914742  | Validation accuracy:  0.9756838905775076\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "dt_train_cm = metrics.confusion_matrix(y_train, dt_preds_train)\n",
    "dt_train_accuracy = metrics.accuracy_score(y_train,dt_preds_train)\n",
    "print('The train confusion matrix for Decision Tree model is:', '\\n', dt_train_cm)\n",
    "\n",
    "dt_val_cm = metrics.confusion_matrix(y_val,dt_preds_val)\n",
    "dt_val_accuracy = metrics.accuracy_score(y_val,dt_preds_val)\n",
    "print('The validation confusion matrix for Decision Tree model is:', '\\n', dt_val_cm)\n",
    "\n",
    "print('Train accuracy: ',dt_train_accuracy,' | Validation accuracy: ',dt_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d910122f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train confusion matrix for K-NN model is: \n",
      " [[523   2]\n",
      " [ 35   3]]\n",
      "The validation confusion matrix for K-NN model is: \n",
      " [[1249    1]\n",
      " [  66    0]]\n",
      "Train accuracy:  0.9342806394316163  | Validation accuracy:  0.9490881458966566\n"
     ]
    }
   ],
   "source": [
    "knn_train_cm = metrics.confusion_matrix(y_train, knn_preds_train)\n",
    "knn_train_accuracy = metrics.accuracy_score(y_train,knn_preds_train)\n",
    "print('The train confusion matrix for K-NN model is:', '\\n', knn_train_cm)\n",
    "\n",
    "knn_val_cm = metrics.confusion_matrix(y_val,knn_preds_val)\n",
    "knn_val_accuracy = metrics.accuracy_score(y_val,knn_preds_val)\n",
    "print('The validation confusion matrix for K-NN model is:', '\\n', knn_val_cm)\n",
    "\n",
    "print('Train accuracy: ',knn_train_accuracy,' | Validation accuracy: ',knn_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5174f8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train confusion matrix for Logistic Regression model is: \n",
      " [[523   2]\n",
      " [  3  35]]\n",
      "The validation confusion matrix for Logistic Regression model is: \n",
      " [[1244    6]\n",
      " [   5   61]]\n",
      "Train accuracy:  0.9911190053285968  | Validation accuracy:  0.9916413373860182\n"
     ]
    }
   ],
   "source": [
    "lr_train_cm = metrics.confusion_matrix(y_train, lr_preds_train)\n",
    "lr_train_accuracy = metrics.accuracy_score(y_train,lr_preds_train)\n",
    "print('The train confusion matrix for Logistic Regression model is:', '\\n', lr_train_cm)\n",
    "\n",
    "lr_val_cm = metrics.confusion_matrix(y_val,lr_preds_val)\n",
    "lr_val_accuracy = metrics.accuracy_score(y_val,lr_preds_val)\n",
    "print('The validation confusion matrix for Logistic Regression model is:', '\\n', lr_val_cm)\n",
    "\n",
    "print('Train accuracy: ',lr_train_accuracy,' | Validation accuracy: ',lr_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cb7c0386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  has the best accuracy:  0.9916413373860182\n"
     ]
    }
   ],
   "source": [
    "accuracies = [dt_val_accuracy,knn_val_accuracy,lr_val_accuracy]\n",
    "best_accuracy = np.max(accuracies)\n",
    "accuracy_name = accuracies.index(best_accuracy)\n",
    "print(accuracy_name,' has the best accuracy: ',best_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e500b212",
   "metadata": {},
   "source": [
    "#### => Logistic regression đang cho ra độ đo accuracy cao nhất trên tập validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d9b4df62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with fraud predict:  (23810, 1)\n",
      "Rows with non-fraud predict:  (474311, 1)\n"
     ]
    }
   ],
   "source": [
    "lr_pred_test = lr_model.predict(X_test)\n",
    "\n",
    "# Create result DataFrame\n",
    "result_df = pd.DataFrame({\"fraud\": lr_pred_test})\n",
    "\n",
    "print('Rows with fraud predict: ',result_df[result_df['fraud'] == 1].shape)\n",
    "print('Rows with non-fraud predict: ',result_df[result_df['fraud'] == 0].shape)\n",
    "\n",
    "# Lưu kết quả ra file CSV\n",
    "result_df.to_csv(\"./result/new_result.csv\", index=False)\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408eb8fb",
   "metadata": {},
   "source": [
    "## Tìm kiếm siêu tham số"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcec67e",
   "metadata": {},
   "source": [
    "#### *Mô hình Decision Tree*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1d2ff697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "Best Score: 0.968888888888889\n",
      "Validation Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và tập validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Định nghĩa các giá trị siêu tham số cần tìm kiếm\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],  # Độ sâu tối đa của cây\n",
    "    'min_samples_split': [2, 5, 10],   # Số lượng mẫu tối thiểu cần để chia một nút\n",
    "    'min_samples_leaf': [1, 2, 4]      # Số lượng mẫu tối thiểu ở các lá\n",
    "}\n",
    "\n",
    "# Khởi tạo mô hình cây quyết định\n",
    "dt_model = DecisionTreeClassifier()\n",
    "\n",
    "# Tạo GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=dt_model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Tiến hành tìm kiếm siêu tham số\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# In ra kết quả tốt nhất\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Đánh giá mô hình tốt nhất trên tập validation\n",
    "best_dt_model = grid_search.best_estimator_\n",
    "val_preds = best_dt_model.predict(X_val)\n",
    "print(\"Validation Accuracy:\", metrics.accuracy_score(y_val, val_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc33355",
   "metadata": {},
   "source": [
    "#### *Mô hình K-NN*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a21075eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'metric': 'euclidean', 'n_neighbors': 7, 'weights': 'uniform'}\n",
      "Best Score: 0.928888888888889\n",
      "Validation Accuracy: 0.9469026548672567\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Khởi tạo mô hình\n",
    "model = KNeighborsClassifier()\n",
    "\n",
    "# Định nghĩa lưới các giá trị siêu tham số cần tìm kiếm\n",
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],         # Số lượng hàng xóm gần nhất\n",
    "    'weights': ['uniform', 'distance'],  # Phương pháp tính trọng số cho hàng xóm\n",
    "    'metric': ['euclidean', 'manhattan'] # Phương pháp tính khoảng cách\n",
    "}\n",
    "\n",
    "# Khởi tạo GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Thực hiện tìm kiếm siêu tham số\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Lấy siêu tham số tốt nhất và điểm số tốt nhất\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "\n",
    "best_knn_model = grid_search.best_estimator_\n",
    "val_preds = best_knn_model.predict(X_val)\n",
    "print(\"Validation Accuracy:\", metrics.accuracy_score(y_val, val_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c7a4a8",
   "metadata": {},
   "source": [
    "#### *Mô hình Logistic Regression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b930f90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 100, 'l1_ratio': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Score: 0.9911111111111112\n",
      "Validation Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dangm\\miniconda3\\envs\\hocmay\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "320 fits failed out of a total of 1280.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "160 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dangm\\miniconda3\\envs\\hocmay\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dangm\\miniconda3\\envs\\hocmay\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dangm\\miniconda3\\envs\\hocmay\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "160 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dangm\\miniconda3\\envs\\hocmay\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\dangm\\miniconda3\\envs\\hocmay\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\dangm\\miniconda3\\envs\\hocmay\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 71, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\dangm\\miniconda3\\envs\\hocmay\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.92888889 0.92888889 0.92888889 0.92888889        nan 0.92888889\n",
      "        nan 0.92888889 0.92888889 0.92888889 0.92888889 0.92888889\n",
      "        nan 0.92888889        nan 0.92888889 0.92888889 0.92888889\n",
      " 0.92888889 0.92888889        nan 0.92888889        nan 0.92888889\n",
      " 0.92888889 0.92888889 0.92888889 0.92888889        nan 0.92888889\n",
      "        nan 0.92888889 0.92888889 0.92888889 0.92888889 0.92888889\n",
      "        nan 0.92888889        nan 0.92888889 0.92888889 0.92888889\n",
      " 0.92888889 0.92888889        nan 0.92888889        nan 0.92888889\n",
      " 0.92888889 0.92888889 0.92888889 0.92888889        nan 0.92888889\n",
      "        nan 0.92888889 0.92888889 0.92888889 0.92888889 0.92888889\n",
      "        nan 0.92888889        nan 0.92888889 0.92888889 0.92888889\n",
      " 0.92444444 0.92888889        nan 0.92888889        nan 0.92888889\n",
      " 0.92888889 0.92888889 0.92444444 0.92888889        nan 0.92888889\n",
      "        nan 0.92888889 0.92888889 0.92888889 0.92444444 0.92888889\n",
      "        nan 0.92888889        nan 0.92888889 0.92888889 0.92888889\n",
      " 0.92444444 0.92888889        nan 0.92888889        nan 0.92888889\n",
      " 0.96444444 0.92888889 0.95333333 0.92888889        nan 0.92888889\n",
      "        nan 0.92888889 0.96444444 0.92888889 0.95333333 0.92888889\n",
      "        nan 0.92888889        nan 0.92888889 0.96444444 0.92888889\n",
      " 0.95333333 0.92888889        nan 0.92888889        nan 0.92888889\n",
      " 0.96444444 0.92888889 0.95333333 0.92888889        nan 0.92888889\n",
      "        nan 0.92888889 0.98222222 0.92888889 0.97777778 0.92888889\n",
      "        nan 0.92888889        nan 0.92888889 0.98222222 0.92888889\n",
      " 0.97777778 0.92888889        nan 0.92888889        nan 0.92888889\n",
      " 0.98222222 0.92888889 0.97777778 0.92888889        nan 0.92888889\n",
      "        nan 0.92888889 0.98222222 0.92888889 0.97777778 0.92888889\n",
      "        nan 0.92888889        nan 0.92888889 0.98888889 0.92888889\n",
      " 0.98222222 0.92888889        nan 0.92888889        nan 0.92888889\n",
      " 0.98666667 0.92888889 0.98222222 0.92888889        nan 0.92888889\n",
      "        nan 0.92888889 0.98444444 0.92888889 0.98222222 0.92888889\n",
      "        nan 0.92888889        nan 0.92888889 0.98888889 0.92888889\n",
      " 0.98222222 0.92888889        nan 0.92888889        nan 0.92888889\n",
      " 0.99111111 0.92888889 0.98444444 0.92888889        nan 0.92888889\n",
      "        nan 0.92888889 0.99111111 0.92888889 0.98444444 0.92888889\n",
      "        nan 0.92888889        nan 0.92888889 0.99111111 0.92888889\n",
      " 0.98444444 0.92888889        nan 0.92888889        nan 0.92888889\n",
      " 0.99111111 0.92888889 0.98444444 0.92888889        nan 0.92888889\n",
      "        nan 0.92888889 0.99111111 0.92888889 0.98666667 0.92888889\n",
      "        nan 0.92888889        nan 0.92888889 0.99111111 0.92888889\n",
      " 0.98666667 0.92888889        nan 0.92888889        nan 0.92888889\n",
      " 0.99111111 0.92888889 0.98666667 0.92888889        nan 0.92888889\n",
      "        nan 0.92888889 0.99111111 0.92888889 0.98666667 0.92888889\n",
      "        nan 0.92888889        nan 0.92888889]\n",
      "  warnings.warn(\n",
      "C:\\Users\\dangm\\miniconda3\\envs\\hocmay\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l1)\n",
      "  warnings.warn(\n",
      "C:\\Users\\dangm\\miniconda3\\envs\\hocmay\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Khởi tạo mô hình\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Định nghĩa lưới các giá trị siêu tham số cần tìm kiếm\n",
    "# param_grid = {\n",
    "#     'penalty': ['l1', 'l2'],             # Phương pháp chuẩn hóa (L1 hoặc L2)\n",
    "#     'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000, 10000, 100000, 1000000]  # Tham số điều chuẩn\n",
    "# }\n",
    "param_grid = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'C': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'l1_ratio': [0.1, 0.5, 0.7, 0.9]  # Chỉ có hiệu lực khi penalty='elasticnet'\n",
    "}\n",
    "# Khởi tạo GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy',n_jobs=-1)\n",
    "\n",
    "# Thực hiện tìm kiếm siêu tham số\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Lấy siêu tham số tốt nhất và điểm số tốt nhất\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "\n",
    "best_lr_model = grid_search.best_estimator_\n",
    "val_preds = best_lr_model.predict(X_val)\n",
    "print(\"Validation Accuracy:\", metrics.accuracy_score(y_val, val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2d2e6baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with fraud predict:  (24834, 1)\n",
      "Rows with non-fraud predict:  (473287, 1)\n"
     ]
    }
   ],
   "source": [
    "lr_best_pred_test = best_lr_model.predict(X_test)\n",
    "\n",
    "# Create result DataFrame\n",
    "result_best_df = pd.DataFrame({\"fraud\": lr_best_pred_test})\n",
    "\n",
    "print('Rows with fraud predict: ',result_best_df[result_best_df['fraud'] == 1].shape)\n",
    "print('Rows with non-fraud predict: ',result_best_df[result_best_df['fraud'] == 0].shape)\n",
    "\n",
    "# Lưu kết quả ra file CSV\n",
    "result_df.to_csv(\"./result/new_result_with_hyperparameter.csv\", index=False)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "05bd171e-20b2-4d89-b920-84e11bd0adab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns before dropping:\n",
      "Index(['fraud', 'fraud5'], dtype='object')\n",
      "Columns after dropping:\n",
      "Index(['fraud', 'fraud5'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Đọc tệp CSV\n",
    "df = pd.read_csv(\"./result/DMC-2019-realclass-1.csv\")\n",
    "\n",
    "# Kiểm tra các cột hiện tại trong DataFrame\n",
    "print(\"Columns before dropping:\")\n",
    "print(df.columns)\n",
    "# Tạo danh sách các cột cần giữ lại\n",
    "columns_to_keep = ['fraud', 'fraud5']\n",
    "\n",
    "# Tạo danh sách các cột cần xóa bằng cách lấy tất cả các cột trừ cột cần giữ lại\n",
    "columns_to_drop = [col for col in df.columns if col not in columns_to_keep]\n",
    "\n",
    "# Xóa các cột không cần thiết\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Kiểm tra lại các cột sau khi xóa\n",
    "print(\"Columns after dropping:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Lưu DataFrame đã cập nhật vào tệp CSV mới\n",
    "df.to_csv(\"./result/DMC-2019-realclass-1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "359a5865-e5d1-4547-8dee-3853b0b54ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with fraud predict:  (24834, 1)\n",
      "Rows with non-fraud predict:  (473287, 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Giả sử bạn đã có các giá trị dự đoán từ mô hình logistic regression\n",
    "# lr_best_pred_test = best_lr_model.predict(X_test)\n",
    "\n",
    "# Tạo DataFrame chứa kết quả dự đoán\n",
    "result_best_df = pd.DataFrame({\"fraud5\": lr_best_pred_test})\n",
    "\n",
    "# In thông tin về các dự đoán\n",
    "print('Rows with fraud predict: ', result_best_df[result_best_df['fraud5'] == 1].shape)\n",
    "print('Rows with non-fraud predict: ', result_best_df[result_best_df['fraud5'] == 0].shape)\n",
    "\n",
    "# Đọc tệp DMC-2019-realclass-1.csv\n",
    "original_df = pd.read_csv(\"./result/DMC-2019-realclass-1.csv\")\n",
    "\n",
    "# Kiểm tra xem số lượng hàng có khớp nhau không\n",
    "assert len(original_df) == len(result_best_df), \"Số lượng hàng không khớp giữa hai DataFrame\"\n",
    "\n",
    "# Thêm cột fraud3 vào DataFrame ban đầu\n",
    "original_df['fraud5'] = result_best_df['fraud5']\n",
    "\n",
    "# Lưu DataFrame đã cập nhật vào tệp CSV mới\n",
    "original_df.to_csv(\"./result/DMC-2019-realclass-1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5e71473c-9e7f-4ea6-9614-5d5762942542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[471477   2917]\n",
      " [  1810  21917]]\n",
      "Benefit: 49750\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Đọc dữ liệu từ tệp CSV\n",
    "df = pd.read_csv(\"./result/DMC-2019-realclass-1.csv\")\n",
    "\n",
    "# Trích xuất các giá trị thực tế và dự đoán\n",
    "y_actual = df['fraud'].values\n",
    "y_predict = df['fraud5'].values\n",
    "\n",
    "# Tính toán ma trận nhầm lẫn\n",
    "cm = confusion_matrix(y_actual, y_predict)\n",
    "\n",
    "\n",
    "# Định nghĩa ma trận chi phí\n",
    "cost_matrix = np.array([[0, -5],\n",
    "                        [-25, 5]])\n",
    "\n",
    "# Tính toán lợi ích tổng thể\n",
    "benefit = np.sum(cm * cost_matrix)\n",
    "\n",
    "# In kết quả\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "print(\"Benefit:\", benefit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2801f1-c20f-41e2-89f2-b85251e68c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eabdeff7",
   "metadata": {},
   "source": [
    "#### **So sánh số dự đoán giữa 2 mô hình normal và hyper-parameter applied**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "533e3bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows end up detecting fraud with normal model:  23810\n",
      "Rows end up detecting fraud with hyper-parameter applied model:  24834\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Rows end up detecting fraud with normal model: ',len(result_df[result_df['fraud'] == 1]))\n",
    "print('Rows end up detecting fraud with hyper-parameter applied model: ',len(result_best_df[result_best_df['fraud5'] == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d652500-d4bd-4a0e-9c26-f3d9c8b79fea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb12a56d-0975-4011-9cab-6bc1b0089a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0159a0a1-6f7b-44a9-a1a1-6065471a5427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385230b3-9f93-4fd5-a2a8-cab552b3feed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
